ğŸµ Music Emotion Classification using CNN + LSTM Hybrid Model
Overview
This project is a Music Emotion Classification System that uses a hybrid deep learning model (CNN + LSTM) to classify songs into multiple emotional categories.
The system features a Graphical User Interface (GUI) where users can upload songs and get real-time emotion predictions.

ğŸš€ Features
âœ… Hybrid CNN + LSTM Model: Combines spatial and temporal audio features for accurate classification.

âœ… Multi-Label Emotion Detection: Songs can express multiple emotions at once, and the model captures this complexity.

âœ… User-Friendly GUI:

Upload WAV or MP3 files.

Visual display of predicted emotions with its spectogram.

Real-time probability scores for each emotion category.

âœ… Multiple Emotion Categories:

Happy

Sad

Excited

Relaxed

Stressed

Calm

And more nuanced combinations based on the Russell Emotion Model.

ğŸ› ï¸ Technologies Used
Python

TensorFlow / Keras

CNN + LSTM Hybrid Architecture

Librosa for audio feature extraction

Streamlit

Matplotlib (for visualizations)

ğŸ¤ Contributors

Muskan Gujar

Blayna Fernandes

Vaishnavi Ingale

ğŸ“„ License
This project is open-source and available under the MIT License.
