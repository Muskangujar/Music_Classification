🎵 Music Emotion Classification using CNN + LSTM Hybrid Model
Overview
This project is a Music Emotion Classification System that uses a hybrid deep learning model (CNN + LSTM) to classify songs into multiple emotional categories.
The system features a Graphical User Interface (GUI) where users can upload songs and get real-time emotion predictions.

🚀 Features
✅ Hybrid CNN + LSTM Model: Combines spatial and temporal audio features for accurate classification.

✅ Multi-Label Emotion Detection: Songs can express multiple emotions at once, and the model captures this complexity.

✅ User-Friendly GUI:

Upload WAV or MP3 files.

Visual display of predicted emotions with its spectogram.

Real-time probability scores for each emotion category.

✅ Multiple Emotion Categories:

Happy

Sad

Excited

Relaxed

Stressed

Calm

And more nuanced combinations based on the Russell Emotion Model.

🛠️ Technologies Used
Python

TensorFlow / Keras

CNN + LSTM Hybrid Architecture

Librosa for audio feature extraction

Streamlit

Matplotlib (for visualizations)

🤝 Contributors

Muskan Gujar

Blayna Fernandes

Vaishnavi Ingale

📄 License
This project is open-source and available under the MIT License.
